{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tri-Model Asymmetric Distillation (Enhanced with Logits Distillation) ‚Äî Sports-in-the-Wild\n",
    "\n",
    "## New Features Added:\n",
    "- **Logits Distillation**: Direct knowledge transfer from teacher/assistant final predictions to student\n",
    "- **Separate Temperature Control**: Independent temperature settings for feature vs logits distillation\n",
    "- **Asymmetric Logits Weighting**: Different weights for teacher vs assistant logits contributions\n",
    "- **Enhanced Loss Tracking**: Detailed metrics for all distillation components\n",
    "\n",
    "## Knowledge Transfer Pathways:\n",
    "1. **Feature Distillation**: Hidden representations ‚Üí Student learns internal feature maps\n",
    "2. **Attention Distillation**: Attention patterns ‚Üí Student learns where to focus\n",
    "3. **Logits Distillation** (NEW): Final predictions ‚Üí Student learns decision-making\n",
    "4. **Classification Loss**: Ground truth ‚Üí Student learns target task\n",
    "\n",
    "This enhanced setup provides more comprehensive knowledge transfer and better utilization of both teacher models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tri-Model Asymmetric Distillation (Multiclass) ‚Äî Sports-in-the-Wild\n",
    "\n",
    "This notebook trains a compact student VideoMAE model on Sports-in-the-Wild using tri-model asymmetric distillation:\n",
    "- Teacher: `mitegvg/videomae-base-finetuned-kinetics-finetuned-sports-videos-in-the-wild`\n",
    "- Assistant: `mitegvg/videomae-base-finetuned-ucf101-finetuned-sports-videos-in-the-wild`\n",
    "- Student (pretrained): `mitegvg/videomae-tiny-finetuned-kinetics-finetuned-sports-videos-in-the-wild`\n",
    "\n",
    "Major differences vs. XD-Violence setup:\n",
    "- Multiclass labels derived from `processed_dataset/*.csv` (no binary mapping)\n",
    "- Slightly different distillation weights that tend to work better for multiclass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\order\\.conda\\envs\\videomae\\lib\\site-packages\\torchvision\\transforms\\functional_tensor.py:5: UserWarning: The torchvision.transforms.functional_tensor module is deprecated in 0.15 and will be **removed in 0.17**. Please don't rely on it. You probably just need to use APIs in torchvision.transforms.functional or in torchvision.transforms.v2.functional.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0+cu118\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# Environment\n",
    "import os\n",
    "import json\n",
    "import torch\n",
    "from transformers import TrainingArguments\n",
    "\n",
    "# Local tri-model modules\n",
    "from tri_model_distillation.config import TriModelConfig\n",
    "from tri_model_distillation.models import TriModelDistillationFramework\n",
    "from tri_model_distillation.trainer import TriModelDistillationTrainer, compute_video_classification_metrics\n",
    "from tri_model_distillation.utils import (\n",
    "    setup_logging, load_label_mappings, create_data_loaders,\n",
    "    print_model_info, save_training_config\n",
    ")\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes (30): ['archery', 'baseball', 'basketball', 'bmx', 'bowling', 'boxing', 'cheerleading', 'discusthrow', 'diving', 'football', 'golf', 'gymnastics', 'hammerthrow', 'highjump', 'hockey', 'hurdling', 'javelin', 'longjump', 'polevault', 'rowing', 'running', 'shotput', 'skating', 'skiing', 'soccer', 'swimming', 'tennis', 'volleyball', 'weight', 'wrestling'] \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Import required for datetime\n",
    "from datetime import datetime\n",
    "# Paths and dataset settings\n",
    "DATASET_ROOT = \"processed_dataset\"\n",
    "OUTPUT_DIR = f\"./tri_model_distilled_sports_multiclass_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
    "\n",
    "# Detect labels for multiclass\n",
    "label2id, id2label = load_label_mappings(dataset_root=DATASET_ROOT, train_csv=\"train.csv\", classification_type=\"multiclass\")\n",
    "num_labels = len(label2id)\n",
    "print(f\"Classes ({num_labels}):\", list(label2id.keys())[:100], (\"...\" if num_labels > 100 else \"\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Tri-Model Configuration with Logits Distillation:\n",
      "   üéØ Classification loss weight: 1.0\n",
      "   üß† Feature distillation weight: 0.05\n",
      "   üëÅÔ∏è Attention distillation weight: 0.05\n",
      "   üìä Logits distillation weight: 0.8\n",
      "   üå°Ô∏è Feature temperature: 4.0\n",
      "   üìà Logits temperature: 3.0\n",
      "   üë®‚Äçüè´ Teacher logits weight: 1.0\n",
      "   ü§ù Assistant logits weight: 0.6\n"
     ]
    }
   ],
   "source": [
    "# Tri-model configuration with logits distillation\n",
    "tri_config = TriModelConfig(\n",
    "    classification_type=\"multiclass\", \n",
    "    num_labels=num_labels,\n",
    "    teacher_model_name=\"mitegvg/videomae-base-finetuned-kinetics-finetuned-sports-videos-in-the-wild\",\n",
    "    assistant_model_name=\"mitegvg/videomae-base-finetuned-ucf101-finetuned-sports-videos-in-the-wild\",\n",
    "    student_model_name=\"mitegvg/videomae-tiny-finetuned-kinetics-finetuned-sports-videos-in-the-wild\",\n",
    "    \n",
    "    # Loss weights - including logits distillation\n",
    "    classification_loss_weight=1.0, \n",
    "    feature_distillation_weight=0.05,  \n",
    "    attention_distillation_weight=0.05,\n",
    "    logits_distillation_weight=0.8,  # NEW: Strong logits distillation for knowledge transfer\n",
    "    \n",
    "    # Temperature settings\n",
    "    temperature=4.0,  # Higher temperature for softer knowledge transfer in multiclass\n",
    "    logits_temperature=3.0,  # NEW: Separate temperature for logits (often lower than feature temp)\n",
    "    \n",
    "    # Asymmetric weights\n",
    "    teacher_feature_weight=1.0,  # Full weight for primary teacher\n",
    "    assistant_feature_weight=0.6,  # Moderate weight for assistant (from UCF101)\n",
    "    teacher_logits_weight=1.0,  # NEW: Full weight for teacher logits\n",
    "    assistant_logits_weight=0.6,  # NEW: Moderate weight for assistant logits\n",
    "    \n",
    "    # Training stability\n",
    "    use_pretrained_student=True,  # Confirmed this is already True by default\n",
    "    num_frames=16,  # Standard for VideoMAE\n",
    ")\n",
    "\n",
    "print(\"üîß Tri-Model Configuration with Logits Distillation:\")\n",
    "print(f\"   üéØ Classification loss weight: {tri_config.classification_loss_weight}\")\n",
    "print(f\"   üß† Feature distillation weight: {tri_config.feature_distillation_weight}\")\n",
    "print(f\"   üëÅÔ∏è Attention distillation weight: {tri_config.attention_distillation_weight}\")\n",
    "print(f\"   üìä Logits distillation weight: {tri_config.logits_distillation_weight}\")\n",
    "print(f\"   üå°Ô∏è Feature temperature: {tri_config.temperature}\")\n",
    "print(f\"   üìà Logits temperature: {tri_config.logits_temperature}\")\n",
    "print(f\"   üë®‚Äçüè´ Teacher logits weight: {tri_config.teacher_logits_weight}\")\n",
    "print(f\"   ü§ù Assistant logits weight: {tri_config.assistant_logits_weight}\")\n",
    "\n",
    "# Calculate optimal batch size and steps based on dataset size\n",
    "total_train_samples = 3364  # Number of lines in train.csv (from wc -l command)\n",
    "batch_size = 4 if torch.cuda.is_available() else 2\n",
    "gradient_accumulation_steps = 8 if torch.cuda.is_available() else 4\n",
    "effective_batch_size = batch_size * gradient_accumulation_steps\n",
    "\n",
    "# Calculate training steps\n",
    "num_epochs = 20\n",
    "steps_per_epoch = total_train_samples // effective_batch_size\n",
    "total_training_steps = steps_per_epoch * num_epochs\n",
    "warmup_steps = min(500, int(0.1 * total_training_steps))\n",
    "\n",
    "# Evaluation frequency\n",
    "eval_steps = max(50, steps_per_epoch // 10)\n",
    "save_steps = max(100, steps_per_epoch // 5)\n",
    "\n",
    "per_device_train_batch_size=batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 22:12:23,094 - tri_model_distillation.models - INFO - Initializing Tri-Model Distillation Framework for multiclass classification...\n",
      "2025-08-19 22:12:23,096 - tri_model_distillation.models - INFO - Loading teacher model...\n",
      "2025-08-19 22:12:25,004 - tri_model_distillation.models - INFO - Loading assistant model...\n",
      "2025-08-19 22:12:25,005 - tri_model_distillation.models - INFO - Loading assistant model from HuggingFace: mitegvg/videomae-base-finetuned-ucf101-finetuned-sports-videos-in-the-wild\n",
      "2025-08-19 22:12:26,878 - tri_model_distillation.models - INFO - Loading student model with label alignment...\n",
      "2025-08-19 22:12:27,030 - tri_model_distillation.models - INFO - All label mappings match perfectly!\n",
      "2025-08-19 22:12:27,031 - tri_model_distillation.models - INFO - Label mappings actually match - loading pretrained model directly\n",
      "2025-08-19 22:12:28,535 - tri_model_distillation.utils - INFO - Loaded 3364 video paths from train.csv\n",
      "2025-08-19 22:12:28,553 - tri_model_distillation.utils - INFO - Loaded 420 video paths from val.csv\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher: {'name': 'mitegvg/videomae-base-finetuned-kinetics-finetuned-sports-videos-in-the-wild', 'num_parameters': 86250270, 'trainable_parameters': 0}\n",
      "Assistant: {'name': 'mitegvg/videomae-base-finetuned-ucf101-finetuned-sports-videos-in-the-wild', 'num_parameters': 86250270, 'trainable_parameters': 0}\n",
      "Student: {'name': 'mitegvg/videomae-tiny-finetuned-kinetics-finetuned-sports-videos-in-the-wild', 'num_parameters': 7698846, 'trainable_parameters': 7698846}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-19 22:12:28,572 - tri_model_distillation.utils - INFO - Loaded 422 video paths from test.csv\n",
      "2025-08-19 22:12:28,573 - tri_model_distillation.utils - INFO - Created data loaders:\n",
      "2025-08-19 22:12:28,574 - tri_model_distillation.utils - INFO -   Train: 3364 samples, 841 batches\n",
      "2025-08-19 22:12:28,575 - tri_model_distillation.utils - INFO -   Val: 420 samples, 105 batches\n",
      "2025-08-19 22:12:28,575 - tri_model_distillation.utils - INFO -   Test: 422 samples, 106 batches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Checking model compatibility for logits distillation...\n",
      "   üë®‚Äçüè´ Teacher model: 30 classes\n",
      "   ü§ù Assistant model: 30 classes\n",
      "   üéì Student model: 30 classes\n",
      "‚úÖ All models have matching output dimensions - logits distillation will work correctly\n"
     ]
    }
   ],
   "source": [
    "# Initialize framework and data loaders\n",
    "setup_logging()\n",
    "\n",
    "framework = TriModelDistillationFramework(\n",
    "    config=tri_config,\n",
    "    num_labels=num_labels,\n",
    "    label2id=label2id,\n",
    "    id2label=id2label\n",
    ")\n",
    "\n",
    "model_info = framework.get_model_info()\n",
    "print(\"Teacher:\", model_info['teacher'])\n",
    "print(\"Assistant:\", model_info['assistant'])\n",
    "print(\"Student:\", model_info['student'])\n",
    "\n",
    "train_loader, val_loader, test_loader = create_data_loaders(\n",
    "    dataset_root=DATASET_ROOT,\n",
    "    image_processor=framework.image_processor,\n",
    "    label2id=label2id,\n",
    "    batch_size=per_device_train_batch_size,  # Add keyword argument name\n",
    "    num_frames=tri_config.num_frames,\n",
    "    num_workers=2,\n",
    ")\n",
    "\n",
    "# Add this cell before the training cell in your notebook\n",
    "\n",
    "def check_model_compatibility(framework):\n",
    "    \"\"\"\n",
    "    Check if teacher, assistant, and student models have compatible output dimensions\n",
    "    for logits distillation.\n",
    "    \"\"\"\n",
    "    print(\"üîç Checking model compatibility for logits distillation...\")\n",
    "    \n",
    "    # Get number of labels from each model\n",
    "    teacher_labels = framework.teacher_model.config.num_labels\n",
    "    assistant_labels = framework.assistant_model.config.num_labels  \n",
    "    student_labels = framework.student_model.config.num_labels\n",
    "    \n",
    "    print(f\"   üë®‚Äçüè´ Teacher model: {teacher_labels} classes\")\n",
    "    print(f\"   ü§ù Assistant model: {assistant_labels} classes\") \n",
    "    print(f\"   üéì Student model: {student_labels} classes\")\n",
    "    \n",
    "    # Check compatibility\n",
    "    models_match = (teacher_labels == student_labels and \n",
    "                   assistant_labels == student_labels)\n",
    "    \n",
    "    if models_match:\n",
    "        print(\"‚úÖ All models have matching output dimensions - logits distillation will work correctly\")\n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è WARNING: Models have different output dimensions!\")\n",
    "        print(\"   üìä Logits distillation may fail due to dimension mismatch\")\n",
    "        print(\"   üí° Consider:\")\n",
    "        print(\"      - Using models with same number of classes\")\n",
    "        print(\"      - Reducing logits_distillation_weight to 0.0\")\n",
    "        print(\"      - Adding dimension alignment (advanced)\")\n",
    "        \n",
    "        # Ask user what to do\n",
    "        response = input(\"\\n‚ùì Continue training anyway? (y/n): \").lower().strip()\n",
    "        return response in ['y', 'yes']\n",
    "\n",
    "# Check compatibility before training\n",
    "if not check_model_compatibility(framework):\n",
    "    print(\"üõë STOP: Training stopped due to model incompatibility\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Training Arguments Configuration:\n",
      "   üìä Logging steps: 10\n",
      "   üìà Eval steps: 50\n",
      "   üíæ Save steps: 100\n",
      "   üîÑ Disable tqdm: False\n",
      "   üìù Report to: ['tensorboard']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using auto half precision backend\n",
      "***** Running training *****\n",
      "  Num examples = 3,364\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 8\n",
      "  Total optimization steps = 2,100\n",
      "  Number of trainable parameters = 7,698,846\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting training with enhanced progress tracking...\n",
      "   üì¶ Total training samples: 3364\n",
      "   üî¢ Steps per epoch: 105\n",
      "   üìä Total training steps: 2100\n",
      "   üìà Evaluation every 50 steps\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2100' max='2100' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2100/2100 8:50:06, Epoch 19/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-100\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-100\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-100\\preprocessor_config.json\n",
      "2025-08-19 22:36:19,405 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-100\n",
      "2025-08-19 22:36:19,406 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-100\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-200\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-200\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-200\\preprocessor_config.json\n",
      "2025-08-19 23:01:20,612 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-200\n",
      "2025-08-19 23:01:20,614 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-200\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-300\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-300\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-300\\preprocessor_config.json\n",
      "2025-08-19 23:26:24,086 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-300\n",
      "2025-08-19 23:26:24,089 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-300\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-400\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-400\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-400\\preprocessor_config.json\n",
      "2025-08-19 23:51:27,857 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-400\n",
      "2025-08-19 23:51:27,857 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-400\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-100] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-500\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-500\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-500\\preprocessor_config.json\n",
      "2025-08-20 00:16:34,169 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-500\n",
      "2025-08-20 00:16:34,170 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-500\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-300] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-600\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-600\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-600\\preprocessor_config.json\n",
      "2025-08-20 00:41:37,192 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-600\n",
      "2025-08-20 00:41:37,193 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-600\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-400] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-700\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-700\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-700\\preprocessor_config.json\n",
      "2025-08-20 01:06:39,021 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-700\n",
      "2025-08-20 01:06:39,023 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-700\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-500] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-800\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-800\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-800\\preprocessor_config.json\n",
      "2025-08-20 01:31:37,477 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-800\n",
      "2025-08-20 01:31:37,479 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-800\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-600] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-900\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-900\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-900\\preprocessor_config.json\n",
      "2025-08-20 01:56:36,912 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-900\n",
      "2025-08-20 01:56:36,913 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-900\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-700] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1000\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1000\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1000\\preprocessor_config.json\n",
      "2025-08-20 02:21:36,302 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1000\n",
      "2025-08-20 02:21:36,303 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1000\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-800] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1100\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1100\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1100\\preprocessor_config.json\n",
      "2025-08-20 02:46:38,002 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1100\n",
      "2025-08-20 02:46:38,003 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1100\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-900] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1200\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1200\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1200\\preprocessor_config.json\n",
      "2025-08-20 03:11:40,929 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1200\n",
      "2025-08-20 03:11:40,931 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1200\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1000] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1300\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1300\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1300\\preprocessor_config.json\n",
      "2025-08-20 03:36:46,318 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1300\n",
      "2025-08-20 03:36:46,319 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1300\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1100] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1400\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1400\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1400\\preprocessor_config.json\n",
      "2025-08-20 04:01:51,261 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1400\n",
      "2025-08-20 04:01:51,261 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1400\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1200] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1500\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1500\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1500\\preprocessor_config.json\n",
      "2025-08-20 04:27:06,507 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1500\n",
      "2025-08-20 04:27:06,508 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1500\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1300] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1600\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1600\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1600\\preprocessor_config.json\n",
      "2025-08-20 04:52:18,789 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1600\n",
      "2025-08-20 04:52:18,790 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1600\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1400] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1700\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1700\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1700\\preprocessor_config.json\n",
      "2025-08-20 05:17:33,913 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1700\n",
      "2025-08-20 05:17:33,914 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1700\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1500] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1800\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1800\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1800\\preprocessor_config.json\n",
      "2025-08-20 05:43:11,428 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1800\n",
      "2025-08-20 05:43:11,429 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1800\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1600] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1900\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1900\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1900\\preprocessor_config.json\n",
      "2025-08-20 06:08:20,980 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1900\n",
      "2025-08-20 06:08:20,981 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1900\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1700] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2000\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2000\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2000\\preprocessor_config.json\n",
      "2025-08-20 06:33:54,008 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2000\n",
      "2025-08-20 06:33:54,008 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2000\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1800] due to args.save_total_limit\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2100\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2100\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2100\\preprocessor_config.json\n",
      "2025-08-20 06:59:19,103 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2100\n",
      "2025-08-20 06:59:19,104 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-2100\n",
      "Deleting older checkpoint [tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-1900] due to args.save_total_limit\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./tri_model_distilled_sports_multiclass_20250819_221210\\checkpoint-200 (score: 0.46190476190476193).\n",
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_221210\\preprocessor_config.json\n",
      "2025-08-20 07:02:51,003 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_221210\n",
      "2025-08-20 07:02:51,005 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_221210\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Training completed!\n",
      "TrainOutput(global_step=2100, training_loss=74.92511500767299, metrics={'train_runtime': 31818.1307, 'train_samples_per_second': 2.115, 'train_steps_per_second': 0.066, 'total_flos': 7.417056438565208e+18, 'train_loss': 74.92511500767299, 'model/student_params': 7698846, 'model/teacher_params': 86250270, 'model/assistant_params': 86250270, 'epoch': 19.81807372175981})\n",
      "Validation: {'eval_loss': 81.8785909016927, 'eval_classification_loss': 1.9278553687390827, 'eval_feature_distillation_loss': 726.9948137555804, 'eval_attention_distillation_loss': 0.0006310126101154657, 'eval_logits_distillation_loss': 9.03512229465303, 'eval_accuracy': 0.46190476190476193, 'eval_precision_macro': 0.4425534664044221, 'eval_precision_micro': 0.46190476190476193, 'eval_precision_weighted': 0.44952711140161866, 'eval_recall_macro': 0.4478836659842852, 'eval_recall_micro': 0.46190476190476193, 'eval_recall_weighted': 0.46190476190476193, 'eval_f1_macro': 0.4308998345290826, 'eval_f1_micro': 0.46190476190476193, 'eval_f1_weighted': 0.44194645887127854, 'eval_roc_auc_ovr': 0.91736304743755, 'eval_roc_auc_ovo': 0.915797224345061, 'eval_cohen_kappa': 0.4410651089663945, 'eval_balanced_accuracy': 0.4478836659842852, 'eval_top1_accuracy': 0.46190476190476193, 'eval_precision': 0.4425534664044221, 'eval_recall': 0.4478836659842852, 'eval_f1_score': 0.4308998345290826, 'eval_class_0_accuracy': 0.5, 'eval_class_0_f1': 0.42857142857142855, 'eval_class_1_accuracy': 0.23529411764705882, 'eval_class_1_f1': 0.27586206896551724, 'eval_class_2_accuracy': 0.5, 'eval_class_2_f1': 0.5333333333333333, 'eval_class_3_accuracy': 0.25, 'eval_class_3_f1': 0.30303030303030304, 'eval_class_4_accuracy': 0.6470588235294118, 'eval_class_4_f1': 0.6111111111111112, 'eval_class_5_accuracy': 0.16666666666666666, 'eval_class_5_f1': 0.26666666666666666, 'eval_class_6_accuracy': 0.47368421052631576, 'eval_class_6_f1': 0.5, 'eval_class_7_accuracy': 0.25, 'eval_class_7_f1': 0.21428571428571427, 'eval_class_8_accuracy': 0.625, 'eval_class_8_f1': 0.625, 'eval_class_9_accuracy': 0.4666666666666667, 'eval_class_9_f1': 0.5, 'eval_class_10_accuracy': 0.4444444444444444, 'eval_class_10_f1': 0.5, 'eval_class_11_accuracy': 0.7647058823529411, 'eval_class_11_f1': 0.6666666666666666, 'eval_class_12_accuracy': 0.25, 'eval_class_12_f1': 0.23529411764705882, 'eval_class_13_accuracy': 0.3, 'eval_class_13_f1': 0.2727272727272727, 'eval_class_14_accuracy': 0.6666666666666666, 'eval_class_14_f1': 0.5, 'eval_class_15_accuracy': 0.5, 'eval_class_15_f1': 0.41025641025641024, 'eval_class_16_accuracy': 0.1111111111111111, 'eval_class_16_f1': 0.15384615384615385, 'eval_class_17_accuracy': 0.15384615384615385, 'eval_class_17_f1': 0.21052631578947367, 'eval_class_18_accuracy': 0.6666666666666666, 'eval_class_18_f1': 0.45714285714285713, 'eval_class_19_accuracy': 0.5555555555555556, 'eval_class_19_f1': 0.5263157894736842, 'eval_avg_class_accuracy': 0.42636834828398296, 'eval_avg_class_f1': 0.4095318104756826, 'eval_top5_accuracy': 0.7857142857142857, 'eval_confusion_matrix_trace': 194.0, 'eval_confusion_matrix_total': 420.0, 'eval_num_samples': 420, 'eval_num_classes': 30, 'eval_classification_type': 'multiclass'}\n",
      "Test: {'test_loss': 82.77582517506387, 'test_classification_loss': 1.867796693650467, 'test_feature_distillation_loss': 740.5295436190203, 'test_attention_distillation_loss': 0.0006283278603512811, 'test_logits_distillation_loss': 8.540062285147572, 'test_accuracy': 0.46919431279620855, 'test_precision_macro': 0.435667525383952, 'test_precision_micro': 0.46919431279620855, 'test_precision_weighted': 0.464469622549716, 'test_recall_macro': 0.44991634216386006, 'test_recall_micro': 0.46919431279620855, 'test_recall_weighted': 0.46919431279620855, 'test_f1_macro': 0.42500336420233514, 'test_f1_micro': 0.46919431279620855, 'test_f1_weighted': 0.45019472028640084, 'test_roc_auc_ovr': 0.9256573353140986, 'test_roc_auc_ovo': 0.9221565311170966, 'test_cohen_kappa': 0.44870381710553175, 'test_balanced_accuracy': 0.44991634216386006, 'test_top1_accuracy': 0.46919431279620855, 'test_precision': 0.435667525383952, 'test_recall': 0.44991634216386006, 'test_f1_score': 0.42500336420233514, 'test_class_0_accuracy': 0.5384615384615384, 'test_class_0_f1': 0.5384615384615384, 'test_class_1_accuracy': 0.2222222222222222, 'test_class_1_f1': 0.32, 'test_class_2_accuracy': 0.4166666666666667, 'test_class_2_f1': 0.47619047619047616, 'test_class_3_accuracy': 0.2727272727272727, 'test_class_3_f1': 0.35294117647058826, 'test_class_4_accuracy': 0.6, 'test_class_4_f1': 0.5217391304347826, 'test_class_5_accuracy': 0.0, 'test_class_5_f1': 0.0, 'test_class_6_accuracy': 0.3684210526315789, 'test_class_6_f1': 0.45161290322580644, 'test_class_7_accuracy': 0.5, 'test_class_7_f1': 0.26666666666666666, 'test_class_8_accuracy': 0.5454545454545454, 'test_class_8_f1': 0.5217391304347826, 'test_class_9_accuracy': 0.65, 'test_class_9_f1': 0.5652173913043478, 'test_class_10_accuracy': 0.5454545454545454, 'test_class_10_f1': 0.5454545454545454, 'test_class_11_accuracy': 0.7058823529411765, 'test_class_11_f1': 0.43636363636363634, 'test_class_12_accuracy': 0.3125, 'test_class_12_f1': 0.38461538461538464, 'test_class_13_accuracy': 0.25, 'test_class_13_f1': 0.3333333333333333, 'test_class_14_accuracy': 0.7857142857142857, 'test_class_14_f1': 0.6666666666666666, 'test_class_15_accuracy': 0.35714285714285715, 'test_class_15_f1': 0.37037037037037035, 'test_class_16_accuracy': 0.6, 'test_class_16_f1': 0.5454545454545454, 'test_class_17_accuracy': 0.23076923076923078, 'test_class_17_f1': 0.23076923076923078, 'test_class_18_accuracy': 0.42857142857142855, 'test_class_18_f1': 0.2, 'test_class_19_accuracy': 0.5294117647058824, 'test_class_19_f1': 0.6, 'test_avg_class_accuracy': 0.4429699881731615, 'test_avg_class_f1': 0.41637980631083504, 'test_top5_accuracy': 0.8080568720379147, 'test_confusion_matrix_trace': 198.0, 'test_confusion_matrix_total': 422.0, 'test_num_samples': 422, 'test_num_classes': 30, 'test_classification_type': 'multiclass'}\n"
     ]
    }
   ],
   "source": [
    "# Trainer and training loop - FIXED for proper progress display AND live per-epoch reporting\n",
    "\n",
    "# Use the config's method to create training arguments\n",
    "training_args = tri_config.to_training_args(\n",
    "    per_device_train_batch_size=per_device_train_batch_size,\n",
    "    per_device_eval_batch_size=per_device_train_batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    warmup_steps=warmup_steps,\n",
    "    \n",
    "    # FIXED: Per-epoch evaluation and logging for live table\n",
    "    evaluation_strategy=\"epoch\",  # Changed from \"steps\" to \"epoch\"\n",
    "    logging_strategy=\"epoch\",     # Changed from \"steps\" to \"epoch\"\n",
    "    logging_steps=10,  # Still useful for within-epoch progress\n",
    "    logging_first_step=True,  # Log the first step\n",
    "    \n",
    "    # FIXED: Save configuration (keeping steps for more frequent saves)\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=save_steps,\n",
    "    save_total_limit=3,  # Keep only 3 checkpoints\n",
    "    \n",
    "    # FIXED: Progress display settings for live reporting\n",
    "    disable_tqdm=False,  # Enable progress bars\n",
    "    report_to=[\"tensorboard\"],  # Enable tensorboard for live tracking\n",
    "    logging_dir=f\"{OUTPUT_DIR}/logs\",\n",
    "    \n",
    "    # FIXED: Metrics configuration\n",
    "    metric_for_best_model=\"eval_accuracy\",\n",
    "    greater_is_better=True,\n",
    "    load_best_model_at_end=True,\n",
    "    \n",
    "    # FIXED: Memory and performance settings\n",
    "    remove_unused_columns=False,\n",
    "    dataloader_pin_memory=True,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    dataloader_num_workers=0,  # Set to 0 for debugging\n",
    "    \n",
    "    # FIXED: Output settings\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    overwrite_output_dir=True,\n",
    "    \n",
    "    # FIXED: Gradient settings\n",
    "    gradient_accumulation_steps=gradient_accumulation_steps,\n",
    "    max_grad_norm=1.0,\n",
    "    \n",
    "    # FIXED: Additional logging\n",
    "    log_level=\"info\",\n",
    "    logging_nan_inf_filter=True,\n",
    ")\n",
    "\n",
    "# Print configuration for verification\n",
    "print(\"üîß Training Arguments Configuration:\")\n",
    "print(f\"   üìä Logging strategy: {training_args.logging_strategy}\")\n",
    "print(f\"   üìà Evaluation strategy: {training_args.evaluation_strategy}\")\n",
    "print(f\"   üíæ Save steps: {training_args.save_steps}\")\n",
    "print(f\"   üîÑ Disable tqdm: {training_args.disable_tqdm}\")\n",
    "print(f\"   üìù Report to: {training_args.report_to}\")\n",
    "\n",
    "# Create trainer with enhanced logging\n",
    "trainer = TriModelDistillationTrainer(\n",
    "    framework=framework,\n",
    "    distillation_config=tri_config,\n",
    "    args=training_args,\n",
    "    train_dataset=train_loader.dataset,\n",
    "    eval_dataset=val_loader.dataset,\n",
    "    compute_metrics=lambda eval_pred, **kwargs: compute_video_classification_metrics(\n",
    "        eval_pred, \n",
    "        classification_type=kwargs.get('classification_type', 'multiclass')\n",
    "    ),\n",
    ")\n",
    "\n",
    "# BONUS: Force notebook training tracker for live HTML table\n",
    "from transformers.integrations import NotebookTrainingTrackerCallback\n",
    "trainer.add_callback(NotebookTrainingTrackerCallback())\n",
    "print(\"‚úÖ Added NotebookTrainingTrackerCallback for live per-epoch table\")\n",
    "\n",
    "# FIXED: Enable detailed progress tracking\n",
    "print(\"üöÄ Starting training with enhanced progress tracking...\")\n",
    "print(f\"   üì¶ Total training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"   üî¢ Steps per epoch: {steps_per_epoch}\")\n",
    "print(f\"   üìä Total training steps: {total_training_steps}\")\n",
    "print(f\"   üìà Evaluation every epoch (instead of every {eval_steps} steps)\")\n",
    "print(f\"   üìã Live per-epoch table will appear below during training\")\n",
    "\n",
    "train_result = trainer.train()\n",
    "print(\"‚úÖ Training completed!\")\n",
    "print(train_result)\n",
    "\n",
    "# Save model and config\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "\n",
    "# Evaluate\n",
    "val_metrics = trainer.evaluate(eval_dataset=val_loader.dataset)\n",
    "print(\"Validation:\", val_metrics)\n",
    "\n",
    "test_metrics = trainer.evaluate(eval_dataset=test_loader.dataset, metric_key_prefix=\"test\")\n",
    "print(\"Test:\", test_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in ./tri_model_distilled_sports_multiclass_20250819_174836\\config.json\n",
      "Model weights saved in ./tri_model_distilled_sports_multiclass_20250819_174836\\model.safetensors\n",
      "Image processor saved in ./tri_model_distilled_sports_multiclass_20250819_174836\\preprocessor_config.json\n",
      "2025-08-19 18:39:01,536 - tri_model_distillation.models - INFO - Student model saved to ./tri_model_distilled_sports_multiclass_20250819_174836\n",
      "2025-08-19 18:39:01,537 - tri_model_distillation.trainer - INFO - Tri-model distillation framework saved to ./tri_model_distilled_sports_multiclass_20250819_174836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./tri_model_distilled_sports_multiclass_20250819_174836\n"
     ]
    }
   ],
   "source": [
    "# Save the final model to the correct directory\n",
    "final_output_dir = OUTPUT_DIR\n",
    "trainer.save_model(final_output_dir)\n",
    "print(f\"Model saved to {final_output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./tri_model_distilled_sports_multiclass_20250819_174836\\config.json\n",
      "Model config VideoMAEConfig {\n",
      "  \"architectures\": [\n",
      "    \"VideoMAEForVideoClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"decoder_hidden_size\": 384,\n",
      "  \"decoder_intermediate_size\": 1536,\n",
      "  \"decoder_num_attention_heads\": 6,\n",
      "  \"decoder_num_hidden_layers\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"archery\",\n",
      "    \"1\": \"baseball\",\n",
      "    \"2\": \"basketball\",\n",
      "    \"3\": \"bmx\",\n",
      "    \"4\": \"bowling\",\n",
      "    \"5\": \"boxing\",\n",
      "    \"6\": \"cheerleading\",\n",
      "    \"7\": \"discusthrow\",\n",
      "    \"8\": \"diving\",\n",
      "    \"9\": \"football\",\n",
      "    \"10\": \"golf\",\n",
      "    \"11\": \"gymnastics\",\n",
      "    \"12\": \"hammerthrow\",\n",
      "    \"13\": \"highjump\",\n",
      "    \"14\": \"hockey\",\n",
      "    \"15\": \"hurdling\",\n",
      "    \"16\": \"javelin\",\n",
      "    \"17\": \"longjump\",\n",
      "    \"18\": \"polevault\",\n",
      "    \"19\": \"rowing\",\n",
      "    \"20\": \"running\",\n",
      "    \"21\": \"shotput\",\n",
      "    \"22\": \"skating\",\n",
      "    \"23\": \"skiing\",\n",
      "    \"24\": \"soccer\",\n",
      "    \"25\": \"swimming\",\n",
      "    \"26\": \"tennis\",\n",
      "    \"27\": \"volleyball\",\n",
      "    \"28\": \"weight\",\n",
      "    \"29\": \"wrestling\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"archery\": 0,\n",
      "    \"baseball\": 1,\n",
      "    \"basketball\": 2,\n",
      "    \"bmx\": 3,\n",
      "    \"bowling\": 4,\n",
      "    \"boxing\": 5,\n",
      "    \"cheerleading\": 6,\n",
      "    \"discusthrow\": 7,\n",
      "    \"diving\": 8,\n",
      "    \"football\": 9,\n",
      "    \"golf\": 10,\n",
      "    \"gymnastics\": 11,\n",
      "    \"hammerthrow\": 12,\n",
      "    \"highjump\": 13,\n",
      "    \"hockey\": 14,\n",
      "    \"hurdling\": 15,\n",
      "    \"javelin\": 16,\n",
      "    \"longjump\": 17,\n",
      "    \"polevault\": 18,\n",
      "    \"rowing\": 19,\n",
      "    \"running\": 20,\n",
      "    \"shotput\": 21,\n",
      "    \"skating\": 22,\n",
      "    \"skiing\": 23,\n",
      "    \"soccer\": 24,\n",
      "    \"swimming\": 25,\n",
      "    \"tennis\": 26,\n",
      "    \"volleyball\": 27,\n",
      "    \"weight\": 28,\n",
      "    \"wrestling\": 29\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_ratio\": 0.0,\n",
      "  \"model_type\": \"videomae\",\n",
      "  \"norm_pix_loss\": true,\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_frames\": 16,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"patch_size\": 16,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"tubelet_size\": 2,\n",
      "  \"use_mean_pooling\": true\n",
      "}\n",
      "\n",
      "loading weights file ./tri_model_distilled_sports_multiclass_20250819_174836\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from ./tri_model_distilled_sports_multiclass_20250819_174836 for evaluation...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing VideoMAEForVideoClassification.\n",
      "\n",
      "All the weights of VideoMAEForVideoClassification were initialized from the model checkpoint at ./tri_model_distilled_sports_multiclass_20250819_174836.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use VideoMAEForVideoClassification for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test dataset size: 422 samples\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "326f4cbc75f341298c943fdbe9c2de31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/106 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall accuracy: 0.4573\n",
      "\n",
      "Top 5 best performing classes:\n",
      "  - swimming: 0.9655\n",
      "  - hockey: 0.7857\n",
      "  - gymnastics: 0.7059\n",
      "  - bowling: 0.7000\n",
      "  - skating: 0.6923\n",
      "\n",
      "Bottom 5 classes:\n",
      "  - hurdling: 0.2143\n",
      "  - shotput: 0.1176\n",
      "  - highjump: 0.0625\n",
      "  - boxing: 0.0000\n",
      "  - running: 0.0000\n",
      "Too many classes for confusion matrix visualization\n",
      "\n",
      "Detailed evaluation results saved to ./tri_model_distilled_sports_multiclass_20250819_174836/detailed_evaluation.json\n"
     ]
    }
   ],
   "source": [
    "# Model Evaluation and Analysis\n",
    "# Core ML Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "import sys\n",
    "import logging\n",
    "import warnings\n",
    "import importlib\n",
    "# Set up device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Load the saved model for detailed evaluation\n",
    "student_model_path = OUTPUT_DIR\n",
    "print(f\"Loading model from {student_model_path} for evaluation...\")\n",
    "\n",
    "from transformers import VideoMAEForVideoClassification, VideoMAEImageProcessor\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Load the model\n",
    "student_model = VideoMAEForVideoClassification.from_pretrained(student_model_path)\n",
    "student_model.to(device)\n",
    "student_model.eval()\n",
    "\n",
    "# Evaluate on test dataset with detailed metrics\n",
    "print(f\"Test dataset size: {len(test_loader.dataset)} samples\")\n",
    "\n",
    "# Define a function to compute detailed metrics\n",
    "def compute_detailed_metrics(model, dataloader, id2label):\n",
    "    \"\"\"Compute detailed metrics for model evaluation\"\"\"\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(dataloader, desc=\"Evaluating\"):\n",
    "            inputs = {k: v.to(device) for k, v in batch.items() if k != \"labels\"}\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            \n",
    "            outputs = model(**inputs)\n",
    "            preds = torch.argmax(outputs.logits, dim=-1)\n",
    "            \n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    \n",
    "    # Per-class accuracy\n",
    "    class_accuracy = {}\n",
    "    for i in range(len(id2label)):\n",
    "        class_indices = np.where(np.array(all_labels) == i)[0]\n",
    "        if len(class_indices) > 0:\n",
    "            class_correct = sum(np.array(all_preds)[class_indices] == i)\n",
    "            class_accuracy[id2label[i]] = class_correct / len(class_indices)\n",
    "    \n",
    "    # Overall accuracy\n",
    "    accuracy = sum(np.array(all_preds) == np.array(all_labels)) / len(all_labels)\n",
    "    \n",
    "    return {\n",
    "        \"confusion_matrix\": cm,\n",
    "        \"class_accuracy\": class_accuracy,\n",
    "        \"overall_accuracy\": accuracy,\n",
    "        \"predictions\": all_preds,\n",
    "        \"labels\": all_labels\n",
    "    }\n",
    "\n",
    "# Run detailed evaluation\n",
    "detailed_metrics = compute_detailed_metrics(student_model, test_loader, id2label)\n",
    "\n",
    "# Display results\n",
    "print(f\"Overall accuracy: {detailed_metrics['overall_accuracy']:.4f}\")\n",
    "print(\"\\nTop 5 best performing classes:\")\n",
    "sorted_classes = sorted(detailed_metrics['class_accuracy'].items(), key=lambda x: x[1], reverse=True)\n",
    "for cls, acc in sorted_classes[:5]:\n",
    "    print(f\"  - {cls}: {acc:.4f}\")\n",
    "\n",
    "print(\"\\nBottom 5 classes:\")\n",
    "for cls, acc in sorted_classes[-5:]:\n",
    "    print(f\"  - {cls}: {acc:.4f}\")\n",
    "\n",
    "# Plot confusion matrix (if not too many classes)\n",
    "if len(id2label) <= 20:  # Only plot if reasonable size\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    disp = ConfusionMatrixDisplay(\n",
    "        confusion_matrix=detailed_metrics['confusion_matrix'],\n",
    "        display_labels=[id2label[i] for i in range(len(id2label))]\n",
    "    )\n",
    "    disp.plot(xticks_rotation=45)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Too many classes for confusion matrix visualization\")\n",
    "\n",
    "# Save results\n",
    "import json\n",
    "with open(f\"{OUTPUT_DIR}/detailed_evaluation.json\", \"w\") as f:\n",
    "    # Convert numpy arrays to lists for JSON serialization\n",
    "    results = {\n",
    "        \"overall_accuracy\": float(detailed_metrics['overall_accuracy']),\n",
    "        \"class_accuracy\": {k: float(v) for k, v in detailed_metrics['class_accuracy'].items()}\n",
    "    }\n",
    "    json.dump(results, f, indent=2)\n",
    "print(f\"\\nDetailed evaluation results saved to {OUTPUT_DIR}/detailed_evaluation.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ./tri_model_distilled_sports_multiclass_20250819_174836\\config.json\n",
      "Model config VideoMAEConfig {\n",
      "  \"architectures\": [\n",
      "    \"VideoMAEForVideoClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"decoder_hidden_size\": 384,\n",
      "  \"decoder_intermediate_size\": 1536,\n",
      "  \"decoder_num_attention_heads\": 6,\n",
      "  \"decoder_num_hidden_layers\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"archery\",\n",
      "    \"1\": \"baseball\",\n",
      "    \"2\": \"basketball\",\n",
      "    \"3\": \"bmx\",\n",
      "    \"4\": \"bowling\",\n",
      "    \"5\": \"boxing\",\n",
      "    \"6\": \"cheerleading\",\n",
      "    \"7\": \"discusthrow\",\n",
      "    \"8\": \"diving\",\n",
      "    \"9\": \"football\",\n",
      "    \"10\": \"golf\",\n",
      "    \"11\": \"gymnastics\",\n",
      "    \"12\": \"hammerthrow\",\n",
      "    \"13\": \"highjump\",\n",
      "    \"14\": \"hockey\",\n",
      "    \"15\": \"hurdling\",\n",
      "    \"16\": \"javelin\",\n",
      "    \"17\": \"longjump\",\n",
      "    \"18\": \"polevault\",\n",
      "    \"19\": \"rowing\",\n",
      "    \"20\": \"running\",\n",
      "    \"21\": \"shotput\",\n",
      "    \"22\": \"skating\",\n",
      "    \"23\": \"skiing\",\n",
      "    \"24\": \"soccer\",\n",
      "    \"25\": \"swimming\",\n",
      "    \"26\": \"tennis\",\n",
      "    \"27\": \"volleyball\",\n",
      "    \"28\": \"weight\",\n",
      "    \"29\": \"wrestling\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"archery\": 0,\n",
      "    \"baseball\": 1,\n",
      "    \"basketball\": 2,\n",
      "    \"bmx\": 3,\n",
      "    \"bowling\": 4,\n",
      "    \"boxing\": 5,\n",
      "    \"cheerleading\": 6,\n",
      "    \"discusthrow\": 7,\n",
      "    \"diving\": 8,\n",
      "    \"football\": 9,\n",
      "    \"golf\": 10,\n",
      "    \"gymnastics\": 11,\n",
      "    \"hammerthrow\": 12,\n",
      "    \"highjump\": 13,\n",
      "    \"hockey\": 14,\n",
      "    \"hurdling\": 15,\n",
      "    \"javelin\": 16,\n",
      "    \"longjump\": 17,\n",
      "    \"polevault\": 18,\n",
      "    \"rowing\": 19,\n",
      "    \"running\": 20,\n",
      "    \"shotput\": 21,\n",
      "    \"skating\": 22,\n",
      "    \"skiing\": 23,\n",
      "    \"soccer\": 24,\n",
      "    \"swimming\": 25,\n",
      "    \"tennis\": 26,\n",
      "    \"volleyball\": 27,\n",
      "    \"weight\": 28,\n",
      "    \"wrestling\": 29\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_ratio\": 0.0,\n",
      "  \"model_type\": \"videomae\",\n",
      "  \"norm_pix_loss\": true,\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_frames\": 16,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"patch_size\": 16,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"tubelet_size\": 2,\n",
      "  \"use_mean_pooling\": true\n",
      "}\n",
      "\n",
      "loading weights file ./tri_model_distilled_sports_multiclass_20250819_174836\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading saved model for inference...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing VideoMAEForVideoClassification.\n",
      "\n",
      "All the weights of VideoMAEForVideoClassification were initialized from the model checkpoint at ./tri_model_distilled_sports_multiclass_20250819_174836.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use VideoMAEForVideoClassification for predictions without further training.\n",
      "loading configuration file ./tri_model_distilled_sports_multiclass_20250819_174836\\preprocessor_config.json\n",
      "Image processor VideoMAEImageProcessor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"do_center_crop\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"VideoMAEImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 224\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Demo inference on test samples:\n",
      "\n",
      "Test video 1: video_000912.mp4\n",
      "Top prediction: gymnastics (confidence: 0.5274)\n",
      "Top 5 predictions:\n",
      "  1. gymnastics: 0.5274\n",
      "  2. boxing: 0.1868\n",
      "  3. cheerleading: 0.1755\n",
      "  4. volleyball: 0.0265\n",
      "  5. wrestling: 0.0241\n",
      "\n",
      "Test video 2: video_000204.mp4\n",
      "Top prediction: tennis (confidence: 0.1549)\n",
      "Top 5 predictions:\n",
      "  1. tennis: 0.1549\n",
      "  2. hammerthrow: 0.1470\n",
      "  3. diving: 0.1365\n",
      "  4. discusthrow: 0.1016\n",
      "  5. golf: 0.0921\n",
      "\n",
      "Test video 3: video_002253.mp4\n",
      "Top prediction: javelin (confidence: 0.4351)\n",
      "Top 5 predictions:\n",
      "  1. javelin: 0.4351\n",
      "  2. hurdling: 0.1197\n",
      "  3. discusthrow: 0.1147\n",
      "  4. running: 0.0886\n",
      "  5. longjump: 0.0637\n",
      "\n",
      "Model inference example completed!\n"
     ]
    }
   ],
   "source": [
    "# Model Inference Demo\n",
    "\n",
    "print(\"Loading saved model for inference...\")\n",
    "inference_model = VideoMAEForVideoClassification.from_pretrained(OUTPUT_DIR)\n",
    "inference_processor = VideoMAEImageProcessor.from_pretrained(OUTPUT_DIR)\n",
    "inference_model.to(device)\n",
    "inference_model.eval()\n",
    "\n",
    "# Function for inference\n",
    "def run_inference(video_path, model, processor, id2label):\n",
    "    \"\"\"Run inference on a single video\"\"\"\n",
    "    try:\n",
    "        import cv2\n",
    "        from tqdm import tqdm\n",
    "        \n",
    "        # Read video\n",
    "        cap = cv2.VideoCapture(video_path)\n",
    "        if not cap.isOpened():\n",
    "            print(f\"Error: Could not open video {video_path}\")\n",
    "            return None\n",
    "        \n",
    "        frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        # Sample frames uniformly\n",
    "        num_frames = 16\n",
    "        frame_indices = np.linspace(0, frame_count - 1, num_frames, dtype=int)\n",
    "        frames = []\n",
    "        \n",
    "        for idx in frame_indices:\n",
    "            cap.set(cv2.CAP_PROP_POS_FRAMES, idx)\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frames.append(frame)\n",
    "        \n",
    "        cap.release()\n",
    "        \n",
    "        if len(frames) != num_frames:\n",
    "            print(f\"Error: Could not extract enough frames from {video_path}\")\n",
    "            return None\n",
    "        \n",
    "        # Process frames\n",
    "        inputs = processor(frames, return_tensors=\"pt\")\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        \n",
    "        # Run inference\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            \n",
    "        # Get predictions\n",
    "        logits = outputs.logits[0]\n",
    "        probs = torch.softmax(logits, dim=0)\n",
    "        \n",
    "        # Get top 5 predictions\n",
    "        top5_probs, top5_indices = torch.topk(probs, 5)\n",
    "        \n",
    "        results = []\n",
    "        for i, (prob, idx) in enumerate(zip(top5_probs.cpu().numpy(), top5_indices.cpu().numpy())):\n",
    "            results.append({\n",
    "                \"rank\": i+1,\n",
    "                \"class\": id2label[idx],\n",
    "                \"probability\": float(prob)\n",
    "            })\n",
    "        \n",
    "        return {\n",
    "            \"top_predictions\": results,\n",
    "            \"top_class\": id2label[top5_indices[0].item()],\n",
    "            \"confidence\": float(top5_probs[0])\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Inference error: {e}\")\n",
    "        return None\n",
    "\n",
    "# Demo on a test sample\n",
    "print(\"\\nDemo inference on test samples:\")\n",
    "\n",
    "# Try to find a few test videos\n",
    "import os\n",
    "import random\n",
    "\n",
    "test_videos = []\n",
    "test_dir = os.path.join(DATASET_ROOT, \"videos\")\n",
    "if os.path.exists(test_dir):\n",
    "    all_videos = [os.path.join(test_dir, f) for f in os.listdir(test_dir) if f.endswith('.mp4')]\n",
    "    test_videos = random.sample(all_videos, min(3, len(all_videos)))\n",
    "\n",
    "if not test_videos:\n",
    "    # Fallback to any video in the dataset\n",
    "    for root, dirs, files in os.walk(DATASET_ROOT):\n",
    "        for file in files:\n",
    "            if file.endswith('.mp4'):\n",
    "                test_videos.append(os.path.join(root, file))\n",
    "                if len(test_videos) >= 3:\n",
    "                    break\n",
    "        if len(test_videos) >= 3:\n",
    "            break\n",
    "\n",
    "# Run inference on test videos\n",
    "if test_videos:\n",
    "    for i, video_path in enumerate(test_videos):\n",
    "        print(f\"\\nTest video {i+1}: {os.path.basename(video_path)}\")\n",
    "        results = run_inference(video_path, inference_model, inference_processor, id2label)\n",
    "        if results:\n",
    "            print(f\"Top prediction: {results['top_class']} (confidence: {results['confidence']:.4f})\")\n",
    "            print(\"Top 5 predictions:\")\n",
    "            for pred in results['top_predictions']:\n",
    "                print(f\"  {pred['rank']}. {pred['class']}: {pred['probability']:.4f}\")\n",
    "else:\n",
    "    print(\"No test videos found. Please check your dataset paths.\")\n",
    "\n",
    "print(\"\\nModel inference example completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Analyzing feature alignment between models...\n",
      "Feature alignment visualization failed: all the input array dimensions except for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 768 and the array at index 2 has size 384\n",
      "\n",
      "Feature alignment analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Feature Alignment Analysis\n",
    "\n",
    "print(\"\\nAnalyzing feature alignment between models...\")\n",
    "\n",
    "# Import visualization libraries if needed\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def visualize_feature_alignment(framework, sample_batch, id2label):\n",
    "    \"\"\"Visualize feature alignment between teacher, assistant, and student models\"\"\"\n",
    "    # Ensure models are in eval mode\n",
    "    framework.teacher_model.eval()\n",
    "    framework.assistant_model.eval()\n",
    "    framework.student_model.eval()\n",
    "    \n",
    "    # Move batch to device\n",
    "    pixel_values = sample_batch[\"pixel_values\"].to(device)\n",
    "    labels = sample_batch[\"labels\"].to(device)\n",
    "    \n",
    "    # Get features from all models\n",
    "    with torch.no_grad():\n",
    "        # Teacher features\n",
    "        teacher_outputs = framework.teacher_model(\n",
    "            pixel_values=pixel_values,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        teacher_features = teacher_outputs.hidden_states[-1][:, 0].cpu().numpy()  # CLS token\n",
    "        \n",
    "        # Assistant features\n",
    "        assistant_outputs = framework.assistant_model(\n",
    "            pixel_values=pixel_values,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        assistant_features = assistant_outputs.hidden_states[-1][:, 0].cpu().numpy()\n",
    "        \n",
    "        # Student features\n",
    "        student_outputs = framework.student_model(\n",
    "            pixel_values=pixel_values,\n",
    "            output_hidden_states=True\n",
    "        )\n",
    "        student_features = student_outputs.hidden_states[-1][:, 0].cpu().numpy()\n",
    "    \n",
    "    # Reduce dimensionality for visualization\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    # Create a combined dataset for PCA\n",
    "    combined_features = np.vstack([teacher_features, assistant_features, student_features])\n",
    "    combined_pca = pca.fit_transform(combined_features)\n",
    "    \n",
    "    # Split back into separate models\n",
    "    batch_size = teacher_features.shape[0]\n",
    "    teacher_pca = combined_pca[:batch_size]\n",
    "    assistant_pca = combined_pca[batch_size:2*batch_size]\n",
    "    student_pca = combined_pca[2*batch_size:]\n",
    "    \n",
    "    # Plot\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    \n",
    "    # Convert labels to class names\n",
    "    label_names = [id2label[l.item()] for l in labels.cpu()]\n",
    "    \n",
    "    # Create scatter plots\n",
    "    plt.scatter(teacher_pca[:, 0], teacher_pca[:, 1], marker='o', s=100, label='Teacher', alpha=0.7)\n",
    "    plt.scatter(assistant_pca[:, 0], assistant_pca[:, 1], marker='s', s=100, label='Assistant', alpha=0.7)\n",
    "    plt.scatter(student_pca[:, 0], student_pca[:, 1], marker='x', s=100, label='Student', alpha=0.7)\n",
    "    \n",
    "    # Add arrows from teacher to student\n",
    "    for i in range(batch_size):\n",
    "        plt.arrow(teacher_pca[i, 0], teacher_pca[i, 1], \n",
    "                 student_pca[i, 0] - teacher_pca[i, 0], \n",
    "                 student_pca[i, 1] - teacher_pca[i, 1],\n",
    "                 color='gray', alpha=0.5, width=0.005)\n",
    "    \n",
    "    # Add labels for each point\n",
    "    for i, label in enumerate(label_names):\n",
    "        plt.annotate(label, \n",
    "                    (student_pca[i, 0], student_pca[i, 1]),\n",
    "                    textcoords=\"offset points\",\n",
    "                    xytext=(0, 10),\n",
    "                    ha='center')\n",
    "    \n",
    "    plt.title('Feature Space Alignment (PCA)')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Calculate and return alignment metrics\n",
    "    teacher_student_dist = np.mean(np.sqrt(np.sum((teacher_features - student_features)**2, axis=1)))\n",
    "    assistant_student_dist = np.mean(np.sqrt(np.sum((assistant_features - student_features)**2, axis=1)))\n",
    "    \n",
    "    return {\n",
    "        \"teacher_student_distance\": teacher_student_dist,\n",
    "        \"assistant_student_distance\": assistant_student_dist,\n",
    "        \"explained_variance\": pca.explained_variance_ratio_.sum()\n",
    "    }\n",
    "\n",
    "# Get a small batch for visualization\n",
    "try:\n",
    "    # Get a small batch from the validation set\n",
    "    sample_batch = next(iter(val_loader))\n",
    "    \n",
    "    # Run feature alignment visualization\n",
    "    alignment_metrics = visualize_feature_alignment(framework, sample_batch, id2label)\n",
    "    \n",
    "    print(\"\\nFeature alignment metrics:\")\n",
    "    print(f\"Teacher-Student distance: {alignment_metrics['teacher_student_distance']:.4f}\")\n",
    "    print(f\"Assistant-Student distance: {alignment_metrics['assistant_student_distance']:.4f}\")\n",
    "    print(f\"PCA explained variance: {alignment_metrics['explained_variance']:.4f}\")\n",
    "    \n",
    "    # Save metrics\n",
    "    with open(f\"{OUTPUT_DIR}/alignment_metrics.json\", \"w\") as f:\n",
    "        json.dump({\n",
    "            \"teacher_student_distance\": float(alignment_metrics['teacher_student_distance']),\n",
    "            \"assistant_student_distance\": float(alignment_metrics['assistant_student_distance']),\n",
    "            \"explained_variance\": float(alignment_metrics['explained_variance'])\n",
    "        }, f, indent=2)\n",
    "    \n",
    "    print(f\"\\nAlignment metrics saved to {OUTPUT_DIR}/alignment_metrics.json\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Feature alignment visualization failed: {e}\")\n",
    "\n",
    "print(\"\\nFeature alignment analysis completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Comparing model architectures...\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model architecture comparison:\n",
      "Teacher: 12 layers, 768 hidden size, 12 heads, 86.3M params\n",
      "Assistant: 12 layers, 768 hidden size, 12 heads, 86.3M params\n",
      "Student: 4 layers, 384 hidden size, 6 heads, 7.7M params\n",
      "\n",
      "Compression ratio (Teacher ‚Üí Student): 11.2x\n",
      "Compression ratio (Assistant ‚Üí Student): 11.2x\n",
      "\n",
      "Architecture comparison saved to ./tri_model_distilled_sports_multiclass_20250819_174836/architecture_comparison.json\n",
      "\n",
      "Model architecture analysis completed!\n"
     ]
    }
   ],
   "source": [
    "# Model Architecture Comparison\n",
    "\n",
    "print(\"\\nComparing model architectures...\")\n",
    "\n",
    "# Get model architectures\n",
    "teacher_config = framework.teacher_model.config\n",
    "assistant_config = framework.assistant_model.config\n",
    "student_config = framework.student_model.config\n",
    "\n",
    "# Extract key parameters\n",
    "models = ['Teacher', 'Assistant', 'Student']\n",
    "hidden_sizes = [teacher_config.hidden_size, assistant_config.hidden_size, student_config.hidden_size]\n",
    "num_layers = [teacher_config.num_hidden_layers, assistant_config.num_hidden_layers, student_config.num_hidden_layers]\n",
    "num_heads = [teacher_config.num_attention_heads, assistant_config.num_attention_heads, student_config.num_attention_heads]\n",
    "params = [\n",
    "    sum(p.numel() for p in framework.teacher_model.parameters()),\n",
    "    sum(p.numel() for p in framework.assistant_model.parameters()),\n",
    "    sum(p.numel() for p in framework.student_model.parameters())\n",
    "]\n",
    "\n",
    "# Create visualization\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Number of layers\n",
    "axes[0, 0].bar(models, num_layers, color=['blue', 'green', 'red'])\n",
    "axes[0, 0].set_title('Number of Transformer Layers')\n",
    "axes[0, 0].set_ylabel('Layers')\n",
    "for i, v in enumerate(num_layers):\n",
    "    axes[0, 0].text(i, v + 0.1, str(v), ha='center')\n",
    "\n",
    "# Plot 2: Hidden size\n",
    "axes[0, 1].bar(models, hidden_sizes, color=['blue', 'green', 'red'])\n",
    "axes[0, 1].set_title('Hidden Size')\n",
    "axes[0, 1].set_ylabel('Dimensions')\n",
    "for i, v in enumerate(hidden_sizes):\n",
    "    axes[0, 1].text(i, v + 10, str(v), ha='center')\n",
    "\n",
    "# Plot 3: Attention heads\n",
    "axes[1, 0].bar(models, num_heads, color=['blue', 'green', 'red'])\n",
    "axes[1, 0].set_title('Attention Heads')\n",
    "axes[1, 0].set_ylabel('Heads')\n",
    "for i, v in enumerate(num_heads):\n",
    "    axes[1, 0].text(i, v + 0.1, str(v), ha='center')\n",
    "\n",
    "# Plot 4: Parameters\n",
    "param_values = [p / 1_000_000 for p in params]  # Convert to millions\n",
    "axes[1, 1].bar(models, param_values, color=['blue', 'green', 'red'])\n",
    "axes[1, 1].set_title('Model Parameters')\n",
    "axes[1, 1].set_ylabel('Millions')\n",
    "for i, v in enumerate(param_values):\n",
    "    axes[1, 1].text(i, v + 0.5, f\"{v:.1f}M\", ha='center')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate compression ratios\n",
    "teacher_student_param_ratio = params[0] / params[2]\n",
    "assistant_student_param_ratio = params[1] / params[2]\n",
    "\n",
    "print(\"\\nModel architecture comparison:\")\n",
    "print(f\"Teacher: {num_layers[0]} layers, {hidden_sizes[0]} hidden size, {num_heads[0]} heads, {params[0]/1_000_000:.1f}M params\")\n",
    "print(f\"Assistant: {num_layers[1]} layers, {hidden_sizes[1]} hidden size, {num_heads[1]} heads, {params[1]/1_000_000:.1f}M params\")\n",
    "print(f\"Student: {num_layers[2]} layers, {hidden_sizes[2]} hidden size, {num_heads[2]} heads, {params[2]/1_000_000:.1f}M params\")\n",
    "print(f\"\\nCompression ratio (Teacher ‚Üí Student): {teacher_student_param_ratio:.1f}x\")\n",
    "print(f\"Compression ratio (Assistant ‚Üí Student): {assistant_student_param_ratio:.1f}x\")\n",
    "\n",
    "# Save architecture comparison\n",
    "with open(f\"{OUTPUT_DIR}/architecture_comparison.json\", \"w\") as f:\n",
    "    json.dump({\n",
    "        \"teacher\": {\n",
    "            \"layers\": int(num_layers[0]),\n",
    "            \"hidden_size\": int(hidden_sizes[0]),\n",
    "            \"attention_heads\": int(num_heads[0]),\n",
    "            \"parameters\": int(params[0])\n",
    "        },\n",
    "        \"assistant\": {\n",
    "            \"layers\": int(num_layers[1]),\n",
    "            \"hidden_size\": int(hidden_sizes[1]),\n",
    "            \"attention_heads\": int(num_heads[1]),\n",
    "            \"parameters\": int(params[1])\n",
    "        },\n",
    "        \"student\": {\n",
    "            \"layers\": int(num_layers[2]),\n",
    "            \"hidden_size\": int(hidden_sizes[2]),\n",
    "            \"attention_heads\": int(num_heads[2]),\n",
    "            \"parameters\": int(params[2])\n",
    "        },\n",
    "        \"compression_ratios\": {\n",
    "            \"teacher_student\": float(teacher_student_param_ratio),\n",
    "            \"assistant_student\": float(assistant_student_param_ratio)\n",
    "        }\n",
    "    }, f, indent=2)\n",
    "\n",
    "print(f\"\\nArchitecture comparison saved to {OUTPUT_DIR}/architecture_comparison.json\")\n",
    "print(\"\\nModel architecture analysis completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file D:\\BIRKBECK\\REPOS\\videomae-base-finetuned-sports-in-the-wild\\tri_model_distilled_sports_multiclass_20250819_221210\\config.json\n",
      "Model config VideoMAEConfig {\n",
      "  \"architectures\": [\n",
      "    \"VideoMAEForVideoClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"decoder_hidden_size\": 384,\n",
      "  \"decoder_intermediate_size\": 1536,\n",
      "  \"decoder_num_attention_heads\": 6,\n",
      "  \"decoder_num_hidden_layers\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"archery\",\n",
      "    \"1\": \"baseball\",\n",
      "    \"2\": \"basketball\",\n",
      "    \"3\": \"bmx\",\n",
      "    \"4\": \"bowling\",\n",
      "    \"5\": \"boxing\",\n",
      "    \"6\": \"cheerleading\",\n",
      "    \"7\": \"discusthrow\",\n",
      "    \"8\": \"diving\",\n",
      "    \"9\": \"football\",\n",
      "    \"10\": \"golf\",\n",
      "    \"11\": \"gymnastics\",\n",
      "    \"12\": \"hammerthrow\",\n",
      "    \"13\": \"highjump\",\n",
      "    \"14\": \"hockey\",\n",
      "    \"15\": \"hurdling\",\n",
      "    \"16\": \"javelin\",\n",
      "    \"17\": \"longjump\",\n",
      "    \"18\": \"polevault\",\n",
      "    \"19\": \"rowing\",\n",
      "    \"20\": \"running\",\n",
      "    \"21\": \"shotput\",\n",
      "    \"22\": \"skating\",\n",
      "    \"23\": \"skiing\",\n",
      "    \"24\": \"soccer\",\n",
      "    \"25\": \"swimming\",\n",
      "    \"26\": \"tennis\",\n",
      "    \"27\": \"volleyball\",\n",
      "    \"28\": \"weight\",\n",
      "    \"29\": \"wrestling\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"archery\": 0,\n",
      "    \"baseball\": 1,\n",
      "    \"basketball\": 2,\n",
      "    \"bmx\": 3,\n",
      "    \"bowling\": 4,\n",
      "    \"boxing\": 5,\n",
      "    \"cheerleading\": 6,\n",
      "    \"discusthrow\": 7,\n",
      "    \"diving\": 8,\n",
      "    \"football\": 9,\n",
      "    \"golf\": 10,\n",
      "    \"gymnastics\": 11,\n",
      "    \"hammerthrow\": 12,\n",
      "    \"highjump\": 13,\n",
      "    \"hockey\": 14,\n",
      "    \"hurdling\": 15,\n",
      "    \"javelin\": 16,\n",
      "    \"longjump\": 17,\n",
      "    \"polevault\": 18,\n",
      "    \"rowing\": 19,\n",
      "    \"running\": 20,\n",
      "    \"shotput\": 21,\n",
      "    \"skating\": 22,\n",
      "    \"skiing\": 23,\n",
      "    \"soccer\": 24,\n",
      "    \"swimming\": 25,\n",
      "    \"tennis\": 26,\n",
      "    \"volleyball\": 27,\n",
      "    \"weight\": 28,\n",
      "    \"wrestling\": 29\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_ratio\": 0.0,\n",
      "  \"model_type\": \"videomae\",\n",
      "  \"norm_pix_loss\": true,\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_frames\": 16,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"patch_size\": 16,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"tubelet_size\": 2,\n",
      "  \"use_mean_pooling\": true\n",
      "}\n",
      "\n",
      "loading configuration file D:\\BIRKBECK\\REPOS\\videomae-base-finetuned-sports-in-the-wild\\tri_model_distilled_sports_multiclass_20250819_221210\\config.json\n",
      "Model config VideoMAEConfig {\n",
      "  \"architectures\": [\n",
      "    \"VideoMAEForVideoClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.0,\n",
      "  \"decoder_hidden_size\": 384,\n",
      "  \"decoder_intermediate_size\": 1536,\n",
      "  \"decoder_num_attention_heads\": 6,\n",
      "  \"decoder_num_hidden_layers\": 4,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.0,\n",
      "  \"hidden_size\": 384,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"archery\",\n",
      "    \"1\": \"baseball\",\n",
      "    \"2\": \"basketball\",\n",
      "    \"3\": \"bmx\",\n",
      "    \"4\": \"bowling\",\n",
      "    \"5\": \"boxing\",\n",
      "    \"6\": \"cheerleading\",\n",
      "    \"7\": \"discusthrow\",\n",
      "    \"8\": \"diving\",\n",
      "    \"9\": \"football\",\n",
      "    \"10\": \"golf\",\n",
      "    \"11\": \"gymnastics\",\n",
      "    \"12\": \"hammerthrow\",\n",
      "    \"13\": \"highjump\",\n",
      "    \"14\": \"hockey\",\n",
      "    \"15\": \"hurdling\",\n",
      "    \"16\": \"javelin\",\n",
      "    \"17\": \"longjump\",\n",
      "    \"18\": \"polevault\",\n",
      "    \"19\": \"rowing\",\n",
      "    \"20\": \"running\",\n",
      "    \"21\": \"shotput\",\n",
      "    \"22\": \"skating\",\n",
      "    \"23\": \"skiing\",\n",
      "    \"24\": \"soccer\",\n",
      "    \"25\": \"swimming\",\n",
      "    \"26\": \"tennis\",\n",
      "    \"27\": \"volleyball\",\n",
      "    \"28\": \"weight\",\n",
      "    \"29\": \"wrestling\"\n",
      "  },\n",
      "  \"image_size\": 224,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1536,\n",
      "  \"label2id\": {\n",
      "    \"archery\": 0,\n",
      "    \"baseball\": 1,\n",
      "    \"basketball\": 2,\n",
      "    \"bmx\": 3,\n",
      "    \"bowling\": 4,\n",
      "    \"boxing\": 5,\n",
      "    \"cheerleading\": 6,\n",
      "    \"discusthrow\": 7,\n",
      "    \"diving\": 8,\n",
      "    \"football\": 9,\n",
      "    \"golf\": 10,\n",
      "    \"gymnastics\": 11,\n",
      "    \"hammerthrow\": 12,\n",
      "    \"highjump\": 13,\n",
      "    \"hockey\": 14,\n",
      "    \"hurdling\": 15,\n",
      "    \"javelin\": 16,\n",
      "    \"longjump\": 17,\n",
      "    \"polevault\": 18,\n",
      "    \"rowing\": 19,\n",
      "    \"running\": 20,\n",
      "    \"shotput\": 21,\n",
      "    \"skating\": 22,\n",
      "    \"skiing\": 23,\n",
      "    \"soccer\": 24,\n",
      "    \"swimming\": 25,\n",
      "    \"tennis\": 26,\n",
      "    \"volleyball\": 27,\n",
      "    \"weight\": 28,\n",
      "    \"wrestling\": 29\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mask_ratio\": 0.0,\n",
      "  \"model_type\": \"videomae\",\n",
      "  \"norm_pix_loss\": true,\n",
      "  \"num_attention_heads\": 6,\n",
      "  \"num_channels\": 3,\n",
      "  \"num_frames\": 16,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"patch_size\": 16,\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"qkv_bias\": true,\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.51.3\",\n",
      "  \"tubelet_size\": 2,\n",
      "  \"use_mean_pooling\": true\n",
      "}\n",
      "\n",
      "loading weights file D:\\BIRKBECK\\REPOS\\videomae-base-finetuned-sports-in-the-wild\\tri_model_distilled_sports_multiclass_20250819_221210\\model.safetensors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting evaluation on the full test set...\n",
      "Attempting to load model from: D:\\BIRKBECK\\REPOS\\videomae-base-finetuned-sports-in-the-wild\\tri_model_distilled_sports_multiclass_20250819_221210\n",
      "Model directory found. Initializing pipeline...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint weights were used when initializing VideoMAEForVideoClassification.\n",
      "\n",
      "All the weights of VideoMAEForVideoClassification were initialized from the model checkpoint at D:\\BIRKBECK\\REPOS\\videomae-base-finetuned-sports-in-the-wild\\tri_model_distilled_sports_multiclass_20250819_221210.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use VideoMAEForVideoClassification for predictions without further training.\n",
      "loading configuration file D:\\BIRKBECK\\REPOS\\videomae-base-finetuned-sports-in-the-wild\\tri_model_distilled_sports_multiclass_20250819_221210\\preprocessor_config.json\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n",
      "Image processor VideoMAEImageProcessor {\n",
      "  \"crop_size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"do_center_crop\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.485,\n",
      "    0.456,\n",
      "    0.406\n",
      "  ],\n",
      "  \"image_processor_type\": \"VideoMAEImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.229,\n",
      "    0.224,\n",
      "    0.225\n",
      "  ],\n",
      "  \"resample\": 2,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pipeline initialized. Using device: cuda:0\n",
      "Loaded 422 samples from processed_dataset\\test.csv\n",
      "\n",
      "Starting inference on 422 test videos...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processed 10/422 videos...\n",
      "  Processed 20/422 videos...\n",
      "  Processed 30/422 videos...\n",
      "  Processed 40/422 videos...\n",
      "  Processed 50/422 videos...\n",
      "  Processed 60/422 videos...\n",
      "  Processed 70/422 videos...\n",
      "  Processed 80/422 videos...\n",
      "  Processed 90/422 videos...\n",
      "  Processed 100/422 videos...\n",
      "  Processed 110/422 videos...\n",
      "  Processed 120/422 videos...\n",
      "  Processed 130/422 videos...\n",
      "  Processed 140/422 videos...\n",
      "  Processed 150/422 videos...\n",
      "  Processed 160/422 videos...\n",
      "  Processed 170/422 videos...\n",
      "  Processed 180/422 videos...\n",
      "  Processed 190/422 videos...\n",
      "  Processed 200/422 videos...\n",
      "  Processed 210/422 videos...\n",
      "  Processed 220/422 videos...\n",
      "  Processed 230/422 videos...\n",
      "  Processed 240/422 videos...\n",
      "  Processed 250/422 videos...\n",
      "  Processed 260/422 videos...\n",
      "  Processed 270/422 videos...\n",
      "  Processed 280/422 videos...\n",
      "  Processed 290/422 videos...\n",
      "  Processed 300/422 videos...\n",
      "  Processed 310/422 videos...\n",
      "  Processed 320/422 videos...\n",
      "  Processed 330/422 videos...\n",
      "  Processed 340/422 videos...\n",
      "  Processed 350/422 videos...\n",
      "  Processed 360/422 videos...\n",
      "  Processed 370/422 videos...\n",
      "  Processed 380/422 videos...\n",
      "  Processed 390/422 videos...\n",
      "  Processed 400/422 videos...\n",
      "  Processed 410/422 videos...\n",
      "  Processed 420/422 videos...\n",
      "  Processed 422/422 videos...\n",
      "\n",
      "--- Evaluation Complete ---\n",
      "Total videos processed: 422\n",
      "Top-1 Correct Predictions: 168\n",
      "Top-5 Correct Predictions: 311\n",
      "Top-1 Accuracy: 39.81%\n",
      "Top-5 Accuracy: 73.70%\n",
      "Average inference time per video: 0.055 seconds (18.21 videos/sec)\n",
      "\n",
      "Detailed Multiclass Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     archery       0.18      0.54      0.27        13\n",
      "    baseball       0.42      0.28      0.33        18\n",
      "  basketball       0.31      0.33      0.32        12\n",
      "         bmx       0.50      0.09      0.15        11\n",
      "     bowling       0.26      0.50      0.34        10\n",
      "      boxing       0.00      0.00      0.00        11\n",
      "cheerleading       0.46      0.63      0.53        19\n",
      " discusthrow       0.17      0.50      0.25         4\n",
      "      diving       0.42      0.73      0.53        11\n",
      "    football       0.48      0.50      0.49        20\n",
      "        golf       0.26      0.64      0.37        11\n",
      "  gymnastics       0.40      0.47      0.43        17\n",
      " hammerthrow       0.31      0.25      0.28        16\n",
      "    highjump       0.33      0.25      0.29        16\n",
      "      hockey       0.44      0.79      0.56        14\n",
      "    hurdling       0.11      0.07      0.09        14\n",
      "     javelin       0.75      0.30      0.43        10\n",
      "    longjump       0.43      0.23      0.30        13\n",
      "   polevault       0.00      0.00      0.00         7\n",
      "      rowing       0.50      0.47      0.48        17\n",
      "     running       0.00      0.00      0.00        11\n",
      "     shotput       0.67      0.12      0.20        17\n",
      "     skating       1.00      0.15      0.27        13\n",
      "      skiing       0.91      0.62      0.74        16\n",
      "      soccer       0.53      0.62      0.57        13\n",
      "    swimming       0.81      0.76      0.79        29\n",
      "      tennis       0.25      0.50      0.33        10\n",
      "  volleyball       0.50      0.42      0.45        24\n",
      "      weight       0.00      0.00      0.00         7\n",
      "   wrestling       0.32      0.33      0.32        18\n",
      "\n",
      "    accuracy                           0.40       422\n",
      "   macro avg       0.39      0.37      0.34       422\n",
      "weighted avg       0.44      0.40      0.38       422\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 7  0  0  0  0  0  1  0  1  1  2  1  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 3  5  1  0  0  0  0  1  0  2  1  0  0  1  0  1  0  2  0  0  0  0  0  0\n",
      "   0  0  0  1  0  0]\n",
      " [ 0  0  4  0  4  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  2  0  0]\n",
      " [ 2  1  0  1  1  0  0  1  0  0  1  0  1  0  0  0  0  0  0  0  1  0  0  0\n",
      "   0  0  1  0  0  1]\n",
      " [ 2  0  3  0  5  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 4  0  0  0  0  0  0  0  0  0  1  1  0  0  0  0  0  0  0  0  0  1  0  0\n",
      "   0  0  1  1  0  2]\n",
      " [ 0  0  0  0  0  0 12  0  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  1  0  3  0  0]\n",
      " [ 1  0  0  0  0  0  0  2  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  1  0  0  0  2]\n",
      " [ 0  0  0  0  0  0  0  0  0 10  6  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   3  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  2  7  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  3  0  0  0  0  8  0  3  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  1  1  1]\n",
      " [ 1  0  0  0  0  0  1  3  1  0  1  0  4  0  2  2  0  0  0  0  0  0  0  0\n",
      "   0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  2  4  0  2  0  0  0  0  0  0  0  0\n",
      "   0  1  4  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0 11  0  0  0  0  0  0  0  0  1\n",
      "   0  0  1  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  1  0  1  0  0  0  2  1  1  1  1  1  0  0  0  0  0\n",
      "   0  0  2  0  0  1]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  1  0  0  1  0  0  3  1  1  0  0  0  0  0\n",
      "   1  0  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  1  0  0  2  0  1  1  0  0  0  0  3  0  2  0  0  0  0\n",
      "   0  0  1  0  0  0]\n",
      " [ 2  1  0  0  0  0  1  1  0  1  0  0  0  0  0  1  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 1  1  0  0  1  1  1  0  0  0  0  0  0  0  0  0  0  0  1  8  0  0  0  0\n",
      "   1  0  2  0  0  0]\n",
      " [ 1  0  0  0  0  0  1  0  0  0  3  0  2  0  0  0  0  0  0  1  0  0  0  0\n",
      "   1  0  0  0  1  1]\n",
      " [ 4  1  0  0  1  0  2  3  1  0  0  0  0  0  0  1  0  0  0  0  0  2  0  0\n",
      "   0  0  0  2  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  1  0  0  0  0  0  7  0  0  0  0  0  0  0  2  0\n",
      "   0  1  0  0  1  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  0  0  4  0  0  0  0  1  0  0  0 10\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  3  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   8  0  0  0  0  1]\n",
      " [ 0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 22  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  3  0  0  0  0\n",
      "   0  1  5  0  0  0]\n",
      " [ 1  0  4  1  4  1  0  0  0  0  0  1  0  1  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 10  0  1]\n",
      " [ 3  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "   0  0  0  0  0  1]\n",
      " [ 5  0  0  0  0  0  2  0  0  0  0  3  1  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  1  0  0  6]]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from transformers import pipeline\n",
    "import torch  # For checking device\n",
    "import time\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"Starting evaluation on the full test set...\")\n",
    "\n",
    "# Define paths (relative to the notebook location)\n",
    "dataset_root_path = \"processed_dataset\"\n",
    "test_csv_filename = \"test.csv\"\n",
    "test_csv_path = os.path.join(dataset_root_path, test_csv_filename)\n",
    "\n",
    "local_model_directory = OUTPUT_DIR\n",
    "absolute_model_path = os.path.abspath(local_model_directory)\n",
    "\n",
    "# Function to load test data (video paths and true labels)\n",
    "def load_test_data_from_csv(csv_file_path, data_root_path):\n",
    "    test_samples = []\n",
    "    if not os.path.exists(csv_file_path):\n",
    "        print(f\"ERROR: Test CSV file not found at {csv_file_path}\")\n",
    "        return test_samples\n",
    "\n",
    "    with open(csv_file_path, \"r\") as f:\n",
    "        for line in f.readlines():\n",
    "            parts = line.strip().split()\n",
    "            if len(parts) >= 2:\n",
    "                relative_video_path = parts[0]  # e.g., \"videos/video_000000.mp4\"\n",
    "                true_label_str = parts[1]\n",
    "\n",
    "                full_video_path = os.path.normpath(os.path.join(data_root_path, relative_video_path))\n",
    "                test_samples.append((full_video_path, true_label_str))\n",
    "            elif line.strip():\n",
    "                print(f\"Warning: Malformed line in {csv_file_path}: '{line.strip()}'\")\n",
    "    print(f\"Loaded {len(test_samples)} samples from {csv_file_path}\")\n",
    "    return test_samples\n",
    "\n",
    "# Initialize the video classification pipeline\n",
    "video_cls = None\n",
    "print(f\"Attempting to load model from: {absolute_model_path}\")\n",
    "if not os.path.isdir(absolute_model_path):\n",
    "    print(f\"ERROR: Model directory not found at {absolute_model_path}\")\n",
    "else:\n",
    "    print(f\"Model directory found. Initializing pipeline...\")\n",
    "    try:\n",
    "        video_cls = pipeline(\n",
    "            task=\"video-classification\",\n",
    "            model=absolute_model_path,\n",
    "            device=0 if torch.cuda.is_available() else -1  # Use GPU if available\n",
    "        )\n",
    "        print(f\"Pipeline initialized. Using device: {'cuda:0' if torch.cuda.is_available() else 'cpu'}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error initializing pipeline: {e}\")\n",
    "\n",
    "if video_cls:\n",
    "    # Load test data\n",
    "    test_data = load_test_data_from_csv(test_csv_path, dataset_root_path)\n",
    "\n",
    "    if test_data:\n",
    "        total_videos_processed = 0\n",
    "        true_labels = []\n",
    "        predicted_labels = []\n",
    "        top1_correct_predictions = 0\n",
    "        top5_correct_predictions = 0\n",
    "        inference_times = []\n",
    "\n",
    "        print(f\"\\nStarting inference on {len(test_data)} test videos...\")\n",
    "        for i, (video_path, true_label) in enumerate(test_data):\n",
    "            if not os.path.exists(video_path):\n",
    "                print(f\"Warning: Video file not found at {video_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                start_time = time.time()\n",
    "                raw_results = video_cls(video_path)\n",
    "                end_time = time.time()\n",
    "                inference_times.append(end_time - start_time)\n",
    "                total_videos_processed += 1\n",
    "\n",
    "                if not raw_results:\n",
    "                    print(f\"Warning: No results returned for video {video_path}. Skipping.\")\n",
    "                    continue\n",
    "\n",
    "                # Extract top-5 predicted labels\n",
    "                top5_results = raw_results[:5]\n",
    "                predicted_labels_top5 = [res['label'].split('-')[0] for res in top5_results]\n",
    "                predicted_label_top1 = predicted_labels_top5[0] if predicted_labels_top5 else None\n",
    "\n",
    "                # Accumulate for per-class report\n",
    "                if predicted_label_top1 is not None:\n",
    "                    predicted_labels.append(predicted_label_top1)\n",
    "                    true_labels.append(true_label)\n",
    "\n",
    "                # Top-k accuracy\n",
    "                if predicted_label_top1 == true_label:\n",
    "                    top1_correct_predictions += 1\n",
    "                if true_label in predicted_labels_top5:\n",
    "                    top5_correct_predictions += 1\n",
    "\n",
    "                if (i + 1) % 10 == 0 or (i + 1) == len(test_data):\n",
    "                    print(f\"  Processed {i + 1}/{len(test_data)} videos...\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"An error occurred during processing of {video_path}: {e}\")\n",
    "\n",
    "        if total_videos_processed > 0:\n",
    "            # Accuracies\n",
    "            top1_accuracy = (top1_correct_predictions / total_videos_processed) * 100\n",
    "            top5_accuracy = (top5_correct_predictions / total_videos_processed) * 100\n",
    "\n",
    "            # Timing\n",
    "            avg_inference_time = sum(inference_times) / len(inference_times)\n",
    "            fps = 1.0 / avg_inference_time if avg_inference_time > 0 else float('inf')\n",
    "\n",
    "            print(\"\\n--- Evaluation Complete ---\")\n",
    "            print(f\"Total videos processed: {total_videos_processed}\")\n",
    "            print(f\"Top-1 Correct Predictions: {top1_correct_predictions}\")\n",
    "            print(f\"Top-5 Correct Predictions: {top5_correct_predictions}\")\n",
    "            print(f\"Top-1 Accuracy: {top1_accuracy:.2f}%\")\n",
    "            print(f\"Top-5 Accuracy: {top5_accuracy:.2f}%\")\n",
    "            print(f\"Average inference time per video: {avg_inference_time:.3f} seconds ({fps:.2f} videos/sec)\")\n",
    "\n",
    "            # Multiclass report/confusion matrix (only for successfully accumulated items)\n",
    "            if len(predicted_labels) == len(true_labels) and len(true_labels) > 0:\n",
    "                print(\"\\nDetailed Multiclass Classification Report:\")\n",
    "                print(classification_report(true_labels, predicted_labels, labels=list(label2id.keys())))\n",
    "\n",
    "                print(\"\\nConfusion Matrix:\")\n",
    "                cm = confusion_matrix(true_labels, predicted_labels, labels=list(label2id.keys()))\n",
    "                print(cm)\n",
    "        else:\n",
    "            print(\"\\n--- Evaluation Complete ---\")\n",
    "            print(\"No videos were processed successfully.\")\n",
    "    else:\n",
    "        print(\"No test data loaded. Cannot perform evaluation.\")\n",
    "else:\n",
    "    print(\"Video classification pipeline not initialized. Cannot perform evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
